{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Models - RNN for Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.cuda as cuda\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Text and Convert to Integer Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "    \n",
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "    \n",
    "        self.whitelist = [chr(i) for i in range(32,127)]\n",
    "    \n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        #tokenize text file\n",
    "        assert os.path.exists(path)\n",
    "        #add words to dictionary\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                line = ''.join([c for c in line if c in self.whitelist])\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "            \n",
    "        #tokenize file content\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            ids = torch.LongTensor(tokens)\n",
    "            token = 0\n",
    "            for line in f:\n",
    "                line = ''.join([c for c in line if c in self.whitelist])\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word2idx[word]\n",
    "                    token += 1\n",
    "        return ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(corpus.dictionary.idx2word[10])\n",
    "print(corpus.dictionary.word2idx['That'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1039900])\n",
      "torch.Size([63420])\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train.size())\n",
    "print(corpus.valid.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'else'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = corpus.train[112]\n",
    "corpus.dictionary.idx2word[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74010\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(corpus.dictionary)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model using GRU Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout=0.5):\n",
    "        \n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "            \n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.drop1(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop2(output)\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return Variable(weight.new(self.num_layers, batch_size, self.hidden_size).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, batch_size):\n",
    "    #How clean can we divide batch into batch_size parts\n",
    "    n_batch = data.size(0) // batch_size\n",
    "    #Trim off elements that wouldn't fit\n",
    "    data = data.narrow(0,0,n_batch*batch_size)\n",
    "    #Evenly divide data\n",
    "    data = data.view(batch_size, -1).t().contiguous()\n",
    "    if cuda.is_available():\n",
    "        data = data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Once          a\n",
      "      upon       good\n",
      "         a       king\n",
      "      time        and\n",
      "     there          a\n",
      "       was      queen\n"
     ]
    }
   ],
   "source": [
    "dummy_data = 'Once upon a time there was a good king and a queen'\n",
    "dummy_data_idx = [corpus.dictionary.word2idx[w] for w in dummy_data.split()]\n",
    "dummy_tensor = torch.LongTensor(dummy_data_idx)\n",
    "op = batchify(dummy_tensor, 2)\n",
    "for row in op:\n",
    "    print('%10s %10s' % (corpus.dictionary.idx2word[row[0]], corpus.dictionary.idx2word[row[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size for train\n",
    "bs_train = 20\n",
    "\n",
    "#batch size for validation\n",
    "bs_valid = 10\n",
    "\n",
    "#number of times to unroll graph for backpropagation through time\n",
    "bptt_size = 35\n",
    "\n",
    "#gradient clipping\n",
    "clip = 0.25\n",
    "\n",
    "#size of embedding vector\n",
    "embed_size = 200\n",
    "\n",
    "#size of hidden state in RNN\n",
    "hidden_size = 200\n",
    "\n",
    "#number of RNN Layers\n",
    "num_layers = 2\n",
    "\n",
    "# percentage of neurons to drop for regularization\n",
    "dropout_pct = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = batchify(corpus.train, bs_train)\n",
    "val_data = batchify(corpus.valid, bs_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51995, 20])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, num_layers, dropout_pct)\n",
    "\n",
    "if cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if cuda.is_available():\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i, evaluation=False):\n",
    "    seq_len = min(bptt_size, len(source)-1-i)\n",
    "    data = Variable(source[i:i+seq_len])\n",
    "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
    "    if cuda.is_available():\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = get_batch(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 20])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([700])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_source, lr):\n",
    "    #Turn on training mode -> enable dropout\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    hidden = model.init_hidden(bs_train)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for batch, i in enumerate(range(0,data_source.size(0) - 1, bptt_size)):\n",
    "        \n",
    "        data, targets = get_batch(data_source, i)\n",
    "        \n",
    "        #To start each batch, detach hidden state from how it was previously produced\n",
    "        hidden = Variable(hidden.data)\n",
    "        \n",
    "        if cuda.is_available():\n",
    "            hidden = hidden.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output.view(-1, vocab_size), targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        #clip_grad_norm prevents exploding gradient\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += len(data) * loss.data\n",
    "        \n",
    "    return total_loss.item() / len(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_source):\n",
    "    #Turn on eval mode -> disable dropout\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    hidden = model.init_hidden(bs_valid)\n",
    "    \n",
    "    for i in range(0, data_source.size(0) - 1, bptt_size):\n",
    "        data, targets = get_batch(data_source, i, evaluation=True)\n",
    "        \n",
    "        if cuda.is_available():\n",
    "            hidden = hidden.cuda()\n",
    "        \n",
    "        output, hidden = model(data, hidden)\n",
    "        output_flat = output.view(-1, vocab_size)\n",
    "        \n",
    "        total_loss += len(data) * criterion(output_flat, targets).data\n",
    "        hidden = Variable(hidden.data)\n",
    "    return total_loss.item() / len(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over epochs\n",
    "best_val_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(epochs, lr):\n",
    "    global best_val_loss\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        train_loss = train(train_data, lr)\n",
    "        val_loss = evaluate(val_data)\n",
    "        print('Train Loss: ', train_loss, 'Valid Loss: ', val_loss)\n",
    "        \n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), './4.model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drake\\Anaconda3\\envs\\Pytorch Deep Learning\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "C:\\Users\\Drake\\Anaconda3\\envs\\Pytorch Deep Learning\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  6.37492126646793 Valid Loss:  6.800919219094923\n",
      "Train Loss:  6.218556471776132 Valid Loss:  6.744746703524125\n",
      "Train Loss:  6.11726007308395 Valid Loss:  6.730186036542101\n",
      "Train Loss:  6.0457069189345125 Valid Loss:  6.743603531023337\n",
      "Train Loss:  5.987822146360227 Valid Loss:  6.745710639388205\n"
     ]
    }
   ],
   "source": [
    "run(5, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 200\n",
    "temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (encoder): Embedding(74010, 200)\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (rnn): GRU(200, 200, num_layers=2, dropout=0.5)\n",
       "  (decoder): Linear(in_features=200, out_features=74010, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(vocab_size, embed_size, hidden_size, num_layers, dropout_pct)\n",
    "model.load_state_dict(torch.load('./4.model1.pth'))\n",
    "\n",
    "if cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#High temperature displays greater linguistic variety, low temperature is more grammatically correct\n",
    "temperature = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seas \n",
      "Were what their another. \n",
      "ALONSO. O, you shall speak the ambition's \n",
      "Out of the yon of my state, that now \n",
      "Will show the people in the phrase of death. \n",
      "ANTONY. Her own, and his gentleman had not neer all? \n",
      "PHEBE. I will be the young pause. \n",
      "KING HENRY. Nay, you have chance \n",
      "That care you may be funeral, \n",
      "The gods it make his ears of true these eyes! \n",
      "Or, thou art your face, in both his Thats \n",
      "And to alter by his royal hands \n",
      "To do you treachery: loss. \n",
      "CHARMIAN. Then, that you have been made \n",
      "As it is the brings of your epitaph \n",
      "And in his English intend and marvellous age, \n",
      "MIRANDA. Do you be off the letter] \n",
      "QUICKLY. I am a man for his faithful wife and the \n",
      "grief, of Rome will there's the cause to trust your of? \n",
      "FIRST WATCH. You cannot be weary, but slight my sight and \n",
      "yours. \n",
      "EVANS. Mine was my gentleman if it shall be a times of \n",
      "the sheep. \n",
      "ANTONY. No, my lord, is a hungry hand. \n"
     ]
    }
   ],
   "source": [
    "hidden = model.init_hidden(1)\n",
    "idx = corpus.dictionary.word2idx['The']\n",
    "input = Variable(torch.LongTensor([[idx]]).long())\n",
    "\n",
    "if cuda.is_available():\n",
    "    input.data = input.data.cuda()\n",
    "\n",
    "print(corpus.dictionary.idx2word[idx], '', end='')\n",
    "\n",
    "for i in range(num_words):\n",
    "    output, hidden = model(input,hidden)\n",
    "    word_weights = output.squeeze().data.div(temperature).exp().cpu()\n",
    "    word_idx = torch.multinomial(word_weights, 1).item()\n",
    "    input.data.fill_(word_idx)\n",
    "    word = corpus.dictionary.idx2word[word_idx]\n",
    "    \n",
    "    if word == '<eos>':\n",
    "        print('')\n",
    "    else:\n",
    "        print(word + ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The King of the \n",
      "world and that I have been a man in the King. \n",
      "\n",
      "Enter SIR SIR MESSENGER \n",
      "\n",
      "Enter the KING, and the MESSENGER \n",
      "\n",
      "FIRST MURDERER. How is a man of this of the \n",
      "King of the King of the King of the world of his \n",
      "own great man of the King's own life and the man of the \n",
      "next of the world of the Duke of the place of his \n",
      "own own eyes and the man of the King and the King of the \n",
      "King's own eyes and the Duke of the world and the of the \n",
      "man of the King of the King of the King of the poor \n",
      "DUKE OF FRANCE. The King is a man and the Duke of the \n",
      "whole of the Duke of the new whole of a man of the \n",
      "company of the other of the King of the King of the \n",
      "French of the King of the other of the King and the man of \n",
      "the of the King of the man of the King of the King's \n",
      "Wales, and the man of "
     ]
    }
   ],
   "source": [
    "hidden = model.init_hidden(1)\n",
    "idx = corpus.dictionary.word2idx['The']\n",
    "input = Variable(torch.LongTensor([[idx]]).long())\n",
    "\n",
    "if cuda.is_available():\n",
    "    input.data = input.data.cuda()\n",
    "\n",
    "print(corpus.dictionary.idx2word[idx], '', end='')\n",
    "\n",
    "for i in range(num_words):\n",
    "    output, hidden = model(input,hidden)\n",
    "    word_weights = output.squeeze().data.div(temperature).exp().cpu()\n",
    "    word_idx = torch.multinomial(word_weights, 1).item()\n",
    "    input.data.fill_(word_idx)\n",
    "    word = corpus.dictionary.idx2word[word_idx]\n",
    "    \n",
    "    if word == '<eos>':\n",
    "        print('')\n",
    "    else:\n",
    "        print(word + ' ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
